{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Assuming timtiffread and smooth_image_and_subtract_background7 are implemented elsewhere\n",
    "\n",
    "class PRISM_Data():\n",
    "    def __init__(self, filedir, channels):\n",
    "        self.filedir = filedir  # holds the file list\n",
    "        self.curFile = \"\"  # holds the name of the current file\n",
    "        self.fileIdx = 0  # holds the index of the current file in fList\n",
    "        self.img = None  # holds the raw image/stack data of the current file\n",
    "        self.smooth = None  # holds the smoothed image/stack data of the current file\n",
    "        # self.isMovie = 0  # 1 if files in the list are movies, 0 if files are individual images\n",
    "        # self.nFrames = 0  # number of frames in current file (if movie)\n",
    "        # self.curFrame = 0  # current frame in current file (if movie)\n",
    "\n",
    "\n",
    "    def setFListFromParams(self, params):\n",
    "        self.reset()\n",
    "        # This method needs to be adapted based on the data loading strategy in Python\n",
    "        # The MATLAB version uses directory and file existence checks and file listing,\n",
    "        # which can be achieved in Python using os.path and os.listdir or glob.glob\n",
    "        # For simplicity, this is left as a placeholder\n",
    "\n",
    "    def setFList(self, fList):\n",
    "        self.reset()\n",
    "        if isinstance(fList, list):\n",
    "            self.fList = fList\n",
    "        else:\n",
    "            print(\"Input file list has wrong format; resetting airlocalize data object.\")\n",
    "\n",
    "    def getFList(self):\n",
    "        return self.fList\n",
    "\n",
    "    def setFileIdx(self, idx):\n",
    "        if idx > len(self.fList) or idx <= 0:\n",
    "            print(f\"Cannot access file index {idx}; file list has {len(self.fList)} entries.\")\n",
    "            return\n",
    "        if idx != self.fileIdx:\n",
    "            self.resetCurrentFile()\n",
    "            self.fileIdx = idx\n",
    "            self.curFile = self.fList[idx - 1]  # -1 for zero-based indexing in Python\n",
    "        else:\n",
    "            if self.curFile != self.fList[idx - 1]:\n",
    "                self.resetCurrentFile()\n",
    "                self.fileIdx = idx\n",
    "                self.curFile = self.fList[idx - 1]\n",
    "\n",
    "    def getFileIdx(self):\n",
    "        return self.fileIdx\n",
    "\n",
    "    def setCurFile(self, fileName):\n",
    "        if fileName not in self.fList:\n",
    "            print(f\"Desired file {fileName} is not part of existing file list; cannot set as current.\")\n",
    "        else:\n",
    "            idx = self.fList.index(fileName) + 1  # +1 to match MATLAB's one-based indexing\n",
    "            self.setFileIdx(idx)\n",
    "\n",
    "    def getCurFile(self):\n",
    "        return self.curFile\n",
    "\n",
    "    def setNFrames(self):\n",
    "        # This method depends on how the image data is loaded and handled in Python\n",
    "        pass\n",
    "\n",
    "    def setCurFrame(self, newFrame):\n",
    "        # Similar to setNFrames, needs adaptation based on Python image handling\n",
    "        pass\n",
    "\n",
    "    def isFileIndexImgLoaded(self, idx):\n",
    "        # Check if an image for a given index is loaded; adapt based on Python logic\n",
    "        pass\n",
    "\n",
    "    def retrieveImg(self, overwrite):\n",
    "        # Adapt based on how images are loaded and managed in Python\n",
    "        pass\n",
    "\n",
    "    def retrieveSmoothedImg(self, params, overwrite):\n",
    "        # Adapt based on image smoothing and background subtraction in Python\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.ndimage import gaussian_filter, generate_binary_structure, binary_dilation\n",
    "from scipy import ndimage\n",
    "\n",
    "def find_isolated_maxima(alData, params, verbose=True):\n",
    "    \"\"\"\n",
    "    Finds local maxima above the threshold in the smoothed image.\n",
    "\n",
    "    Parameters:\n",
    "    - alData: An object-like structure with the attributes 'smooth', 'img', 'isMovie', 'curFrame'.\n",
    "    - params: An object-like structure with 'threshLevel', 'threshUnits', 'minDistBetweenSpots', 'numDim', 'maxSpots'.\n",
    "    - verbose: If True, prints additional information.\n",
    "    \n",
    "    Returns:\n",
    "    - maxima: A list of local maxima coordinates and their intensities.\n",
    "    \"\"\"\n",
    "    # Initialize maxima\n",
    "    maxima = []\n",
    "\n",
    "    # Determine the threshold intensity based on the specified units\n",
    "    if params.threshUnits == 'absolute':\n",
    "        threshInt = params.threshLevel\n",
    "    elif params.threshUnits in ['SD', 'legacySD']:\n",
    "        if not alData.isMovie:\n",
    "            img = alData.img if params.threshUnits == 'SD' else alData.smooth\n",
    "            threshInt = params.threshLevel * np.std(img)\n",
    "        else:\n",
    "            img = alData.img[:,:,alData.curFrame] if params.threshUnits == 'SD' else alData.smooth[:,:,alData.curFrame]\n",
    "            threshInt = params.threshLevel * np.std(img)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported threshold units.\")\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Threshold value is {threshInt} in {params.threshUnits} units.\")\n",
    "\n",
    "    # Find local maxima\n",
    "    smooth_img = alData.smooth if not alData.isMovie else alData.smooth[:,:,alData.curFrame]\n",
    "    footprint = generate_binary_structure(params.numDim, 1)\n",
    "    footprint = ndimage.iterate_structure(footprint, params.minDistBetweenSpots)\n",
    "    local_max = ((smooth_img == ndimage.maximum_filter(smooth_img, footprint=footprint)) & (smooth_img > threshInt))\n",
    "\n",
    "    # Extract coordinates and intensities of the local maxima\n",
    "    coordinates = np.argwhere(local_max)\n",
    "    intensities = smooth_img[local_max]\n",
    "\n",
    "    if params.numDim == 2: maxima = np.column_stack((coordinates, intensities))\n",
    "    elif params.numDim == 3: maxima = np.column_stack((coordinates, intensities))\n",
    "    \n",
    "    # Sort maxima by intensity in descending order and truncate if necessary\n",
    "    maxima = maxima[maxima[:, -1].argsort()[::-1]]\n",
    "    if len(maxima) > params.maxSpots:\n",
    "        maxima = maxima[:params.maxSpots]\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Detected {len(maxima)} spots.\")\n",
    "\n",
    "    return maxima\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predetection of local maxima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "from scipy.ndimage import gaussian_filter, generate_binary_structure, binary_dilation\n",
    "\n",
    "def find_isolated_maxima(alData, params, verbose=False):\n",
    "    \"\"\"\n",
    "    Finds local maxima above the threshold in the smoothed image.\n",
    "\n",
    "    alData: dict containing 'smooth', 'img', 'isMovie', and 'curFrame' keys.\n",
    "    params: dict containing 'threshLevel', 'threshUnits', 'minDistBetweenSpots', 'numDim', and 'maxSpots'.\n",
    "    verbose: boolean, prints additional information if True.\n",
    "\n",
    "    Example usage:\n",
    "        alData = {\n",
    "            'smooth': your_smoothed_image_here,\n",
    "            'img': your_original_image_here,\n",
    "            'isMovie': False,  # or True if it's a movie\n",
    "            'curFrame': 0  # current frame to process if it's a movie\n",
    "        }\n",
    "        params = {\n",
    "            'threshLevel': your_threshold_level,\n",
    "            'threshUnits': 'absolute',  # or 'SD' or 'legacySD'\n",
    "            'minDistBetweenSpots': your_minimum_distance_between_spots,\n",
    "            'numDim': 2,  # or 3 for 3D images\n",
    "            'maxSpots': your_maximum_number_of_spots_allowed\n",
    "        }\n",
    "        maxima = find_isolated_maxima_clean3(alData, params, verbose=True)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve threshold level\n",
    "    if params['threshUnits'] == 'absolute':\n",
    "        threshInt = params['threshLevel']\n",
    "    elif params['threshUnits'] in ['SD', 'legacySD']:\n",
    "        image_to_use = alData.img if params['threshUnits'] == 'SD' else alData.smooth\n",
    "        threshInt = np.mean(image_to_use[image_to_use > 0]) + params['threshLevel'] * np.std(image_to_use[image_to_use > 0])\n",
    "    else: raise ValueError(\"Unsupported threshUnits\")\n",
    "    if verbose: print(f\"Threshold value is {threshInt} in absolute units\")\n",
    "\n",
    "    # Find local maxima\n",
    "    minDist = round(params['minDistBetweenSpots'])\n",
    "    if minDist > 0:\n",
    "        struct_size = [2 * minDist + 1] * params['numdim'] # create the structural element with the desired size\n",
    "        struct = np.ones(struct_size, dtype=bool)\n",
    "        center = tuple([minDist] * params['numdim'])\n",
    "        struct[center] = False  # Setting the center to False\n",
    "        \n",
    "        # image_to_process = alData.img\n",
    "        image_to_process = alData.smooth\n",
    "        local_max = image_to_process >= ndimage.grey_dilation(image_to_process, footprint=struct)\n",
    "    else:\n",
    "        local_max = np.ones_like(image_to_process, dtype=bool)\n",
    "\n",
    "    # Enforce that local maxima intensity is above threshold\n",
    "    local_max &= image_to_process > threshInt\n",
    "\n",
    "    # Store maxima as a list of coordinates / intensity\n",
    "    indices = np.argwhere(local_max)\n",
    "    intensities = image_to_process[local_max]\n",
    "    maxima = np.column_stack((indices, intensities))\n",
    "    \n",
    "    # Ordering the maxima by descending intensity value\n",
    "    maxima = maxima[maxima[:, -1].argsort()[::-1]]\n",
    "\n",
    "    # Truncating the array if it has more spots than allowed\n",
    "    if maxima.shape[0] > params['maxSpots']:\n",
    "        maxima = maxima[:params['maxSpots'], :]\n",
    "        if verbose: print(f\"Predetected {maxima.shape[0]} spots; Truncated to {params['maxSpots']} spots;\")\n",
    "    elif verbose: print(f\"Predetected {maxima.shape[0]} spots;\")\n",
    "\n",
    "    return maxima"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## background correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_ROI_boundaries(stack_size, spot_ctr, cutwidth, thickness, ROI_size):\n",
    "    \"\"\"\n",
    "    Compute the boundaries of an ROI around a spot center in an image stack.\n",
    "\n",
    "    Parameters:\n",
    "    - stack_size: Tuple of integers representing the size of the stack (nx, ny, [nz]).\n",
    "    - spot_ctr: Tuple of floats representing the center of the spot (xc, yc, [zc]).\n",
    "    - cutwidth: Tuple of integers specifying the cut width in pixels.\n",
    "    - thickness: Integer specifying the additional thickness for 'large' ROI.\n",
    "    - ROI_size: String specifying the ROI size ('small' or 'large').\n",
    "\n",
    "    Returns:\n",
    "    - new_ctr: Tuple of new center coordinates within the ROI.\n",
    "    - ROIlimits: Numpy array specifying the min and max bounds of the ROI ([xmin, ymin, (zmin)], [xmax, ymax, (zmax)]).\n",
    "    \"\"\"\n",
    "\n",
    "    # Check input consistency\n",
    "    # print('spot_ctr:', spot_ctr)\n",
    "    if len(stack_size) == 3 and len(spot_ctr) < 3:\n",
    "        print('Cannot compute ROI boundaries, incorrect ROI center coordinates.')\n",
    "        return None, None\n",
    "\n",
    "    # Compute half length of ROI square/cube\n",
    "    if ROI_size == 'small':\n",
    "        halflength = [cutwidth[0]]\n",
    "    elif ROI_size == 'large':\n",
    "        halflength = [cutwidth[0] + thickness]\n",
    "\n",
    "    if len(stack_size) == 3:\n",
    "        halflength.append(cutwidth[1] if ROI_size == 'small' else cutwidth[1] + thickness)\n",
    "\n",
    "    # Compute ROI limits\n",
    "    nx, ny = stack_size[:2]\n",
    "    xc, yc = spot_ctr[:2]\n",
    "    xmin, xmax = np.clip([np.ceil(xc - halflength[0]), np.ceil(xc + halflength[0])], 0, nx-1)\n",
    "    ymin, ymax = np.clip([np.ceil(yc - halflength[0]), np.ceil(yc + halflength[0])], 0, ny-1)\n",
    "    ROIlimits = np.array([[xmin, ymin], [xmax, ymax]])\n",
    "\n",
    "    # Adjust for 3D\n",
    "    if len(stack_size) == 3:\n",
    "        nz = stack_size[2]\n",
    "        zc = spot_ctr[2]\n",
    "        zmin, zmax = np.clip([np.round(zc - halflength[1]), np.round(zc + halflength[1])], 0, nz-1)\n",
    "        ROIlimits = np.hstack((ROIlimits, [[zmin], [zmax]]))\n",
    "\n",
    "    # Compute coordinates of spot center in new region\n",
    "    new_ctr = (xc - xmin + 1, yc - ymin + 1) + ((zc - zmin + 1,) if len(stack_size) == 3 else ())\n",
    "    # print('ROIlimits_in:', ROIlimits.astype(int))\n",
    "    return new_ctr, ROIlimits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tifffile import imsave\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def generate_bg_region_3D(alData, xcenter, ycenter, zcenter, cutwidth_xy, cutwidth_z, thickness):\n",
    "    \"\"\"\n",
    "    Generate the background region for a 3D dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    - alData: A data structure or array containing the image data.\n",
    "    - xcenter, ycenter, zcenter: Center coordinates of the spot.\n",
    "    - cutwidth_xy, cutwidth_z: Cutwidth parameters for defining the ROI.\n",
    "    - thickness: Defines the thickness of the region around the ROI used for background calculation.\n",
    "    \n",
    "    Returns:\n",
    "    - bg: An array of points in the format [x, y, z, intensity], where x, y, z\n",
    "      are pixel positions and intensity is the value from the original image.\n",
    "    \"\"\"\n",
    "    # Ensuring integer values for calculations\n",
    "    thickness = int(abs(thickness))\n",
    "    cutwidth_xy = int(abs(cutwidth_xy))\n",
    "    cutwidth_z = int(abs(cutwidth_z))\n",
    "    nx, ny, nz = alData.img.shape\n",
    "\n",
    "    # Define the ROI based on provided center and cutwidth\n",
    "    xc, yc, zc = np.ceil([xcenter, ycenter, zcenter]).astype(int)\n",
    "    xc = np.clip(xc, 1, nx)\n",
    "    yc = np.clip(yc, 1, ny)\n",
    "    zc = np.clip(zc, 1, nz)\n",
    "    \n",
    "    # Adjusting ranges to Python's 0-based indexing by subtracting 1\n",
    "    x2, y2, z2 = np.clip([xc - cutwidth_xy, yc - cutwidth_xy, zc - cutwidth_z], 0, [nx, ny, nz])\n",
    "    x3, y3, z3 = np.clip([xc + cutwidth_xy, yc + cutwidth_xy, zc + cutwidth_z], 0, [nx, ny, nz])\n",
    "    \n",
    "    # Expand the ROI by 'thickness' pixels to define the region for background calculation\n",
    "    x1, y1, z1 = np.clip([x2 - thickness, y2 - thickness, z2 - thickness], 0, [nx, ny, nz])\n",
    "    x4, y4, z4 = np.clip([x3 + thickness, y3 + thickness, z3 + thickness], 0, [nx, ny, nz])\n",
    "    \n",
    "    # Initialize the background array\n",
    "    bg = []\n",
    "\n",
    "    # Loop over the expanded ROI and collect background pixels\n",
    "    # Including logic to select points within 'thickness' of the ROI\n",
    "    # Similar to the MATLAB loops for collecting bg points\n",
    "    for zpix in range(z1, z4):\n",
    "        for ypix in range(y1, y4):\n",
    "            for xpix in range(x1, x4):\n",
    "                # Check if the current pixel is within the 'thickness' boundary of the ROI\n",
    "                if (xpix < x2 or xpix >= x3) or (ypix < y2 or ypix >= y3) or (zpix < z2 or zpix >= z3):\n",
    "                    bg.append([xpix + 0.5, ypix + 0.5, zpix, alData.img[xpix, ypix, zpix]])\n",
    "\n",
    "    bg = np.array(bg)  # Convert list to numpy array for easier handling\n",
    "    # print(bg.shape, bg.size)\n",
    "    return bg\n",
    "\n",
    "\n",
    "def generate_bg_region_2D(alData, xcenter, ycenter, cutwidth_xy, thickness):\n",
    "    # Adjust for Python's zero-based indexing\n",
    "    thickness = int(abs(thickness))\n",
    "    cutwidth_xy = int(abs(cutwidth_xy))\n",
    "    \n",
    "    # Determine if alData is handling movie data and adjust accordingly\n",
    "    img = alData.img\n",
    "    \n",
    "    nx, ny = img.shape[:2]\n",
    "    npts = 2 * thickness * (2 * (thickness + cutwidth_xy) + 1)\n",
    "    bg = np.zeros((npts+1, 3))\n",
    "    \n",
    "    # Adjust for Python's zero-based indexing\n",
    "    xc = int(np.ceil(xcenter) - 1)\n",
    "    yc = int(np.ceil(ycenter) - 1)\n",
    "    xc = max(0, min(xc, nx-1))\n",
    "    yc = max(0, min(yc, ny-1))\n",
    "    \n",
    "    x2, y2 = max(xc - cutwidth_xy, 0), max(yc - cutwidth_xy, 0)\n",
    "    x3, y3 = min(xc + cutwidth_xy, nx-1), min(yc + cutwidth_xy, ny-1)\n",
    "    \n",
    "    x1, y1 = max(xc - cutwidth_xy - thickness, 0), max(yc - cutwidth_xy - thickness, 0)\n",
    "    x4, y4 = min(xc + cutwidth_xy + thickness, nx-1), min(yc + cutwidth_xy + thickness, ny-1)\n",
    "    \n",
    "    # Collect background points\n",
    "    k = 0\n",
    "    for xpix in range(x1, x4):\n",
    "        for ypix in range(y1, y4):\n",
    "            if (xpix < x2 or xpix > x3) or (ypix < y2 or ypix > y3):\n",
    "                bg[k, 0] = xpix + 0.5  # Adjusting index for human-readable format (origin at 1,1)\n",
    "                bg[k, 1] = ypix + 0.5\n",
    "                bg[k, 2] = img[xpix, ypix]\n",
    "                k += 1\n",
    "\n",
    "    bg = bg[:k, :]  # Trim the unused part of the array\n",
    "    \n",
    "    # Adjust for spatial coordinates (origin at 0,0)\n",
    "    bg[:, 0] -= 0.5\n",
    "    bg[:, 1] -= 0.5\n",
    "    \n",
    "    return bg\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def fit_to_3D_plane(data):\n",
    "    \"\"\"\n",
    "    Fits the intensity I vs. (x,y) to a 3D-hyperplane with equation I = ax + by + c.\n",
    "    Data should be formatted as 3 columns: x, y, intensity, where x, y refer to the\n",
    "    physical coordinates (in pixel units) of the center of the pixel (origin at 0,0\n",
    "    at the corner of the image).\n",
    "    \n",
    "    Parameters:\n",
    "    - data: A numpy array of shape (n, 3) where n is the number of points.\n",
    "    \n",
    "    Returns:\n",
    "    - x: A numpy array containing the coefficients [a, b, c] of the plane.\n",
    "    \"\"\"\n",
    "    # Calculate sums required for the matrix equation\n",
    "    sx = np.sum(data[:, 0])\n",
    "    sy = np.sum(data[:, 1])\n",
    "    sI = np.sum(data[:, 2])\n",
    "    sxx = np.sum(data[:, 0]**2)\n",
    "    syy = np.sum(data[:, 1]**2)\n",
    "    sxy = np.sum(data[:, 0]*data[:, 1])\n",
    "    sIx = np.sum(data[:, 2]*data[:, 0])\n",
    "    sIy = np.sum(data[:, 2]*data[:, 1])\n",
    "    npts = data.shape[0]\n",
    "\n",
    "    # Construct the matrix equation Ax = v for the least squares solution\n",
    "    fitmat = np.array([[sxx, sxy, sx], [sxy, syy, sy], [sx, sy, npts]])\n",
    "    v = np.array([sIx, sIy, sI])\n",
    "\n",
    "    # Solve the matrix equation, handling singular matrix case\n",
    "    try:\n",
    "        x = np.linalg.solve(fitmat, v)\n",
    "    except np.linalg.LinAlgError:  # If matrix inversion is impossible\n",
    "        x = np.array([0, 0, np.mean(data[:, 2])])\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def fit_to_4D_plane(data):\n",
    "    \"\"\"\n",
    "    Fits the intensity I vs. (x,y,z) to a 4D hyperplane with the equation I = ax + by + cz + d.\n",
    "    Data should be formatted as 4 columns: x, y, z, intensity, where x, y, z refer to the\n",
    "    physical coordinates (in pixel units) of the center of the pixel (origin at 0,0,0).\n",
    "    \n",
    "    Parameters:\n",
    "    - data: A numpy array of shape (n, 4) where n is the number of points.\n",
    "    \n",
    "    Returns:\n",
    "    - x: A numpy array containing the coefficients [a, b, c, d] of the plane.\n",
    "    \"\"\"\n",
    "    # Ensure data is in double precision\n",
    "    data = np.array(data, dtype=float)\n",
    "\n",
    "    # Summations required for the matrix equation Ax = v\n",
    "    sx = np.sum(data[:, 0])\n",
    "    sy = np.sum(data[:, 1])\n",
    "    sz = np.sum(data[:, 2])\n",
    "    sI = np.sum(data[:, 3])\n",
    "    \n",
    "    # Summations for squared terms\n",
    "    sxx = np.sum(data[:, 0]**2)\n",
    "    syy = np.sum(data[:, 1]**2)\n",
    "    szz = np.sum(data[:, 2]**2)\n",
    "    \n",
    "    # Summations for product terms\n",
    "    sxy = np.sum(data[:, 0] * data[:, 1])\n",
    "    sxz = np.sum(data[:, 0] * data[:, 2])\n",
    "    syz = np.sum(data[:, 1] * data[:, 2])\n",
    "    \n",
    "    # Summations for product of intensity and coordinates\n",
    "    sIx = np.sum(data[:, 3] * data[:, 0])\n",
    "    sIy = np.sum(data[:, 3] * data[:, 1])\n",
    "    sIz = np.sum(data[:, 3] * data[:, 2])\n",
    "    \n",
    "    # Matrix and vector for the linear system\n",
    "    fitmat = np.array([\n",
    "        [sxx, sxy, sxz, sx],\n",
    "        [sxy, syy, syz, sy],\n",
    "        [sxz, syz, szz, sz],\n",
    "        [sx, sy, sz, data.shape[0]]\n",
    "    ])\n",
    "    v = np.array([sIx, sIy, sIz, sI])\n",
    "\n",
    "    # Solve the system, handling the case of a singular matrix\n",
    "    try:\n",
    "        x = np.linalg.solve(fitmat, v)\n",
    "    except np.linalg.LinAlgError:  # If matrix inversion is impossible\n",
    "        x = np.array([0, 0, 0, np.mean(data[:, 3])])\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def final_3D_plane_small(alData, xc, yc, cutwidth_xy, thickness, plfit, ROIsize):\n",
    "    \"\"\"\n",
    "    Generates a 2D image (pl) where pixel values within a specified ROI around\n",
    "    (xc, yc) are set to values computed by planar interpolation of the background.\n",
    "    \n",
    "    Parameters:\n",
    "    - alData: An object or structure with .img attribute or key containing the image data.\n",
    "              It can be a 2D array or a 3D array for movie data, with an additional .curFrame attribute or key.\n",
    "    - xc, yc: Center coordinates of the ROI in the original image.\n",
    "    - cutwidth_xy: Defines the half-size of the ROI around the center point.\n",
    "    - thickness: Specifies the thickness for ROI boundary calculation.\n",
    "    - plfit: Coefficients [a, b, c] of the plane fitting the background.\n",
    "    - ROIsize: 'small' or 'large', affects the size of the computed ROI.\n",
    "\n",
    "    Returns:\n",
    "    - pl: Interpolated plane values within the ROI.\n",
    "    - stack_bg_corr: The original image corrected by subtracting the interpolated plane.\n",
    "    - new_ctr: New center of the ROI in the corrected image (adjusted for possible image boundary effects).\n",
    "    - ROIlimits: The boundaries of the computed ROI.\n",
    "    \"\"\"\n",
    "    if hasattr(alData, 'isMovie') and alData.isMovie:\n",
    "        img = alData.img[:, :, alData.curFrame]\n",
    "    else:\n",
    "        img = alData.img\n",
    "    \n",
    "    new_ctr, ROIlimits = compute_ROI_boundaries(img.shape[:2], [xc, yc], cutwidth_xy, thickness, ROIsize)\n",
    "    \n",
    "    xmin, xmax = ROIlimits[0, 0], ROIlimits[1, 0]\n",
    "    ymin, ymax = ROIlimits[0, 1], ROIlimits[1, 1]\n",
    "    \n",
    "    pl = np.zeros((xmax-xmin+1, ymax-ymin+1))\n",
    "    stack_bg_corr = np.zeros_like(pl)\n",
    "    \n",
    "    for xpix in range(xmin, xmax+1):\n",
    "        for ypix in range(ymin, ymax+1):\n",
    "            interpolated_value = plfit[0]*(xpix-0.5) + plfit[1]*(ypix-0.5) + plfit[2]\n",
    "            pl[xpix-xmin, ypix-ymin] = interpolated_value\n",
    "            stack_bg_corr[xpix-xmin, ypix-ymin] = img[xpix, ypix] - interpolated_value\n",
    "    \n",
    "    return pl, stack_bg_corr, new_ctr, ROIlimits\n",
    "\n",
    "\n",
    "def final_4D_plane_small(alData, xc, yc, zc, cutwidth_xy, cutwidth_z, thickness, plfit, ROIsize):\n",
    "    \"\"\"\n",
    "    Generates an image pl within an ROI defined around a central spot (xc, yc, zc)\n",
    "    in a 3D image. Pixels within the ROI are set to the values computed by a planar\n",
    "    interpolation of the background surrounding the ROI.\n",
    "    \n",
    "    Parameters:\n",
    "    - alData: Object or dictionary with .img attribute as a 3D numpy array representing the original image data.\n",
    "    - xc, yc, zc: Coordinates of the central spot.\n",
    "    - cutwidth_xy, cutwidth_z: Cutwidth parameters defining the size of the ROI.\n",
    "    - thickness: Not directly used in this function but passed to compute_ROI_boundaries.\n",
    "    - plfit: Coefficients [a, b, c, d] of the plane fitting the background.\n",
    "    - ROIsize: Option ('small' or 'large') that affects ROI boundaries computation.\n",
    "    \n",
    "    Returns:\n",
    "    - pl: Interpolated plane values within the ROI.\n",
    "    - stack_bg_corr: The original image corrected by subtracting the interpolated plane.\n",
    "    - new_ctr: New center of the ROI in the corrected image.\n",
    "    - ROIlimits: Boundaries of the ROI.\n",
    "    \"\"\"\n",
    "    new_ctr, ROIlimits = compute_ROI_boundaries(alData.img.shape, [xc, yc, zc], [cutwidth_xy, cutwidth_z], thickness, ROIsize)\n",
    "\n",
    "    xmin, xmax = int(ROIlimits[0, 0]), int(ROIlimits[1, 0])\n",
    "    ymin, ymax = int(ROIlimits[0, 1]), int(ROIlimits[1, 1])\n",
    "    zmin, zmax = int(ROIlimits[0, 2]), int(ROIlimits[1, 2])\n",
    "\n",
    "    # Initialize the output arrays\n",
    "    # print(xmax, xmin, ymax, ymin, zmax, zmin)\n",
    "    pl = np.zeros((xmax-xmin, ymax-ymin, zmax-zmin))\n",
    "    stack_bg_corr = np.zeros_like(pl)\n",
    "    \n",
    "\n",
    "    xgrid, ygrid, zgrid = np.meshgrid(range(xmin, xmax), range(ymin, ymax), range(zmin, zmax), indexing='ij')\n",
    "\n",
    "    # Calculate interpolated values using vectorized operations\n",
    "    interpolated_values = plfit[0] * (xgrid+0.5) + plfit[1] * (ygrid+0.5) + plfit[2] * zgrid + plfit[3]\n",
    "    # Update 'pl' and 'stack_bg_corr' arrays\n",
    "    pl[:] = interpolated_values\n",
    "    # print(xmin, xmax)\n",
    "    # print(alData.img[xmin:xmax, ymin:ymax, zmin:zmax].shape, interpolated_values.shape, stack_bg_corr.shape)\n",
    "    stack_bg_corr[:] = alData.img[xmin:xmax, ymin:ymax, zmin:zmax] - interpolated_values\n",
    "\n",
    "    # Compute the interpolated plane and corrected image\n",
    "    # for xpix in range(xmin, xmax):\n",
    "    #     for ypix in range(ymin, ymax):\n",
    "    #         for zpix in range(zmin, zmax):\n",
    "    #             interpolated_value = (plfit[0] * (xpix-0.5) + plfit[1] * (ypix-0.5) + plfit[2] * zpix + plfit[3])\n",
    "    #             pl[xpix-xmin, ypix-ymin, zpix-zmin] = interpolated_value\n",
    "    #             stack_bg_corr[xpix-xmin, ypix-ymin, zpix-zmin] = (alData.img[xpix, ypix, zpix] - interpolated_value)\n",
    "\n",
    "    return pl, stack_bg_corr, new_ctr, ROIlimits\n",
    "\n",
    "\n",
    "def gen_linear_interpol(alData, spotCenter, cutwidth, thickness, ROIsize='small'):\n",
    "    numDim = 3 if len(alData.img.shape) == 3 else 2\n",
    "    cutwidth_xy = cutwidth[0]\n",
    "    xc, yc = spotCenter[:2]\n",
    "\n",
    "    if numDim == 3:\n",
    "        if len(cutwidth) < 2:\n",
    "            print(\"3D stack selected but cutwidth parameter has only 1 element; ensure that fit entry is compatible with 3D data.\")\n",
    "            return [np.array([])] * 7  # Return empty arrays for all outputs\n",
    "        cutwidth_xy, cutwidth_z = cutwidth[:2]\n",
    "        \n",
    "        if len(spotCenter) < 3:\n",
    "            print(\"3D stack selected but spot center has only 2 coordinates; ensure that numdim is set to 3.\")\n",
    "            return [np.array([])] * 7  # Return empty arrays for all outputs\n",
    "        \n",
    "        zc = spotCenter[2]\n",
    "        bg = generate_bg_region_3D(alData, spotCenter[0], spotCenter[1], zc, cutwidth_xy, cutwidth_z, thickness=thickness)\n",
    "    else:\n",
    "        # Assuming cutwidth and spotCenter are correctly formatted for 2D\n",
    "        bg = generate_bg_region_2D(alData, spotCenter[0], spotCenter[1], cutwidth[0], thickness)\n",
    "\n",
    "    if bg.size == 0:\n",
    "        if numDim == 3:\n",
    "            plfit = np.zeros(4)  # For 3D data, plfit has 4 elements\n",
    "            new_ctr = np.array([xc, yc, zc])\n",
    "            ROIlimits = np.array([1, 1, 1])\n",
    "        else:\n",
    "            plfit = np.zeros(3)  # For 2D data, plfit has 3 elements\n",
    "            new_ctr = np.array([xc, yc])\n",
    "            ROIlimits = np.array([1, 1])\n",
    "        \n",
    "        pl = np.array([])  # Initialize as an empty array\n",
    "        stack_bg_corr = np.array([])  # Initialize as an empty array\n",
    "        plmean = 0\n",
    "        return pl, stack_bg_corr, new_ctr, ROIlimits, plmean, plfit, bg\n",
    "    \n",
    "\n",
    "    # Fit to a plane based on dimensionality\n",
    "    if numDim == 3: plfit = fit_to_4D_plane(bg)  # bg should be prepared beforehand\n",
    "    else: plfit = fit_to_3D_plane(bg)  # Implement these functions in Python\n",
    "\n",
    "    # Generate corrected images and ROI based on the fitting\n",
    "    if numDim == 3: pl, stack_bg_corr, new_ctr, ROIlimits = final_4D_plane_small(alData, spotCenter[0], spotCenter[1], spotCenter[2], cutwidth[0], cutwidth[1], thickness, plfit, ROIsize)\n",
    "    else: pl, stack_bg_corr, new_ctr, ROIlimits = final_3D_plane_small(alData, spotCenter[0], spotCenter[1], cutwidth[0], thickness, plfit, ROIsize)\n",
    "\n",
    "    # Calculate mean intensity in the ROI\n",
    "    plmean = np.mean(pl)\n",
    "    return pl, stack_bg_corr, new_ctr, ROIlimits, plmean, plfit, bg\n",
    "\n",
    "\n",
    "def subtract_median(alData, spotCenter, cutWidth, thickness, ROIsize, median_type):\n",
    "    \"\"\"\n",
    "    Subtracts the median (local or global) from a specified ROI in an image or movie frame.\n",
    "    \n",
    "    Parameters:\n",
    "    - alData: An object with .img attribute containing the image data and optionally .isMovie and .curFrame for movie data.\n",
    "    - spotCenter: The center of the ROI (x, y, [z]).\n",
    "    - cutWidth: Defines the size of the ROI around the center.\n",
    "    - thickness: Used in calculating ROI boundaries.\n",
    "    - ROIsize: 'small' or 'large', affects the size of the computed ROI.\n",
    "    - median_type: 'local' or 'global', determines the median calculation method.\n",
    "    \n",
    "    Returns:\n",
    "    - pl: An empty array (placeholder for compatibility with other functions).\n",
    "    - stack_bg_corr: The ROI from the image with the median subtracted.\n",
    "    - new_ctr: New center of the ROI (adjusted for possible image boundary effects).\n",
    "    - ROIlimits: The boundaries of the computed ROI.\n",
    "    \"\"\"\n",
    "    img = alData.img\n",
    "\n",
    "    new_ctr, ROIlimits = compute_ROI_boundaries(img.shape, spotCenter, cutWidth, thickness, ROIsize)\n",
    "\n",
    "    # Extract the ROI from the image\n",
    "    stack_bg_corr = img[\n",
    "        ROIlimits[0, 0]:ROIlimits[1, 0] + 1,\n",
    "        ROIlimits[0, 1]:ROIlimits[1, 1] + 1,\n",
    "    ]\n",
    "\n",
    "    # Subtract the median\n",
    "    if median_type == 'local':\n",
    "        median_value = np.median(stack_bg_corr)\n",
    "    elif median_type == 'global':\n",
    "        median_value = np.median(img)\n",
    "    \n",
    "    stack_bg_corr = stack_bg_corr - median_value\n",
    "\n",
    "    pl = np.array([])  # Placeholder, not used in this function\n",
    "    return pl, stack_bg_corr, new_ctr, ROIlimits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gaussian_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import erf\n",
    "\n",
    "\n",
    "def intensity_gaussian3D(xp, yp, zp, x, y, z, sxy, sz, dx, dy, dz):\n",
    "    \"\"\"\n",
    "    Computes the intensity of pixels assuming a standard 3D Gaussian PSF.\n",
    "\n",
    "    Parameters:\n",
    "    - xp, yp, zp: arrays of pixel indices.\n",
    "    - x, y, z: position of the Gaussian center in real units (use dx=dy=dz=1 for pixel units).\n",
    "    - sxy: sigma in the xy-plane in pixels.\n",
    "    - sz: sigma in the z-direction in pixels.\n",
    "    - dx, dy, dz: voxel dimensions in real units.\n",
    "\n",
    "    Returns:\n",
    "    - intensity: a 3D array of the Gaussian intensity values.\n",
    "    \"\"\"\n",
    "    # Computing the center position of each voxel\n",
    "    xp_center = np.ceil(xp) - 0.5\n",
    "    yp_center = np.ceil(yp) - 0.5\n",
    "    zp_center = np.round(zp)\n",
    "    \n",
    "    # Gaussian intensity calculations\n",
    "    gx = np.exp(-((xp_center * dx - x) ** 2) / (2 * sxy ** 2))\n",
    "    gy = np.exp(-((yp_center * dy - y) ** 2) / (2 * sxy ** 2))\n",
    "    gz = np.exp(-((zp_center * dz - z) ** 2) / (2 * sz ** 2))\n",
    "    \n",
    "    intensity = gx * gy * gz\n",
    "    return intensity\n",
    "\n",
    "\n",
    "def intensity_integrated_gaussian3D(xp, yp, zp, x, y, z, sxy, sz, dx, dy, dz):\n",
    "    \"\"\"\n",
    "    Computes the intensity of pixels assuming a 3D Gaussian PSF that is\n",
    "    integrated over each voxel (normalized intensity, i.e., no prefactor).\n",
    "\n",
    "    Parameters:\n",
    "    - xp, yp, zp: arrays of pixel indices.\n",
    "    - x, y, z: position of the Gaussian in real units (if pixels, enter dx=dy=dz=1).\n",
    "    - sxy: sigma in the xy-plane in pixels.\n",
    "    - sz: sigma in the z-direction in pixels.\n",
    "    - dx, dy, dz: voxel dimensions in real units.\n",
    "    \n",
    "    Returns:\n",
    "    - intensity: a 3D array of the Gaussian intensity values integrated over each voxel.\n",
    "    \"\"\"\n",
    "    # Compute the center position of each voxel\n",
    "    xp_center = np.ceil(xp) - 0.5\n",
    "    yp_center = np.ceil(yp) - 0.5\n",
    "    zp_center = np.round(zp)\n",
    "    \n",
    "    # Compute the differences for integration limits\n",
    "    diffx1 = (xp_center - 0.5) * dx - x\n",
    "    diffx2 = (xp_center + 0.5) * dx - x\n",
    "    diffy1 = (yp_center - 0.5) * dy - y\n",
    "    diffy2 = (yp_center + 0.5) * dy - y\n",
    "    diffz1 = (zp_center - 0.5) * dz - z\n",
    "    diffz2 = (zp_center + 0.5) * dz - z\n",
    "    \n",
    "    # Normalize differences by the standard deviations\n",
    "    diffx1 /= np.sqrt(2) * sxy\n",
    "    diffx2 /= np.sqrt(2) * sxy\n",
    "    diffy1 /= np.sqrt(2) * sxy\n",
    "    diffy2 /= np.sqrt(2) * sxy\n",
    "    diffz1 /= np.sqrt(2) * sz\n",
    "    diffz2 /= np.sqrt(2) * sz\n",
    "    \n",
    "    # Calculate the integrated intensity\n",
    "    intensity = np.abs(erf(diffx1) - erf(diffx2)) * \\\n",
    "                np.abs(erf(diffy1) - erf(diffy2)) * \\\n",
    "                np.abs(erf(diffz1) - erf(diffz2))\n",
    "    # print(diffx1.shape, diffx2.shape, \n",
    "    #       diffy1.shape, diffy2.shape, \n",
    "    #       diffz1.shape, diffz2.shape, \n",
    "    #       intensity.shape)\n",
    "    return intensity\n",
    "\n",
    "\n",
    "def intensity_integrated_gaussian3D_stdZ(xp, yp, zp, x, y, z, sxy, sz, dx, dy, dz):\n",
    "    \"\"\"\n",
    "    Computes intensity of pixels assuming a 3D Gaussian PSF that is\n",
    "    integrated over each pixel in the xy-plane; along z, the envelope is that of a standard\n",
    "    Gaussian (no integration).\n",
    "    \n",
    "    Parameters:\n",
    "    - xp, yp, zp: arrays of pixel indices.\n",
    "    - x, y, z: position of the Gaussian in real units (if pixels, enter dx=dy=dz=1).\n",
    "    - sxy: sigma in the xy-plane in pixels.\n",
    "    - sz: sigma in the z direction in pixels.\n",
    "    - dx, dy, dz: voxel dimensions in real units.\n",
    "    \n",
    "    Returns:\n",
    "    - intensity: a 3D array of the Gaussian intensity values.\n",
    "    \"\"\"\n",
    "    # Computing the center position of each voxel\n",
    "    xp_center = np.ceil(xp) - 0.5\n",
    "    yp_center = np.ceil(yp) - 0.5\n",
    "    zp_center = np.round(zp)\n",
    "    \n",
    "    # Calculate differences for erf function in xy plane\n",
    "    diffx1 = (xp_center - 0.5) * dx - x\n",
    "    diffx2 = (xp_center + 0.5) * dx - x\n",
    "    diffy1 = (yp_center - 0.5) * dy - y\n",
    "    diffy2 = (yp_center + 0.5) * dy - y\n",
    "    \n",
    "    # Normalize differences by the standard deviations\n",
    "    diffx1 /= np.sqrt(2) * sxy\n",
    "    diffx2 /= np.sqrt(2) * sxy\n",
    "    diffy1 /= np.sqrt(2) * sxy\n",
    "    diffy2 /= np.sqrt(2) * sxy\n",
    "    \n",
    "    # Gaussian profile in z without integration\n",
    "    gz = np.exp(-((zp_center * dz - z) ** 2) / (2 * sz ** 2))\n",
    "    \n",
    "    # Calculate integrated intensity\n",
    "    intensity = np.abs(erf(diffx1) - erf(diffx2)) * \\\n",
    "                np.abs(erf(diffy1) - erf(diffy2)) * \\\n",
    "                gz\n",
    "    return intensity\n",
    "\n",
    "\n",
    "def intensity_gaussian2D(xp, yp, x, y, sxy, dx, dy):\n",
    "    \"\"\"\n",
    "    Computes the intensity of pixels assuming a standard 2D Gaussian PSF.\n",
    "    \n",
    "    Parameters:\n",
    "    - xp, yp: Arrays of pixel indices.\n",
    "    - x, y: Position of the Gaussian center in real units (use dx=1, dy=1 for pixel units).\n",
    "    - sxy: Sigma for the Gaussian in pixels.\n",
    "    - dx, dy: Pixel dimensions in real units.\n",
    "    \n",
    "    Returns:\n",
    "    - intensity: A 2D array of the Gaussian intensity values.\n",
    "    \"\"\"\n",
    "    # Compute the center position of each pixel\n",
    "    xp_center = np.ceil(xp) - 0.5\n",
    "    yp_center = np.ceil(yp) - 0.5\n",
    "    \n",
    "    # Calculate the Gaussian intensity\n",
    "    gx = np.exp(-((xp_center * dx - x) ** 2) / (2 * sxy ** 2))\n",
    "    gy = np.exp(-((yp_center * dy - y) ** 2) / (2 * sxy ** 2))\n",
    "    intensity = gx * gy\n",
    "    \n",
    "    return intensity\n",
    "\n",
    "\n",
    "def intensity_integrated_gaussian2D(xp, yp, x, y, sxy, dx, dy):\n",
    "    \"\"\"\n",
    "    Computes the intensity of pixels assuming an integrated 2D Gaussian PSF.\n",
    "    \n",
    "    Parameters:\n",
    "    - xp, yp: Arrays of pixel indices.\n",
    "    - x, y: Position of the Gaussian center in real units (use dx=dy=1 for pixel units).\n",
    "    - sxy: Sigma for the Gaussian in pixels.\n",
    "    - dx, dy: Pixel dimensions in real units.\n",
    "    \n",
    "    Returns:\n",
    "    - intensity: A 2D array of the integrated Gaussian intensity values.\n",
    "    \"\"\"\n",
    "    # Adjust xp and yp to the center position of each pixel\n",
    "    xp_center = np.ceil(xp) - 0.5\n",
    "    yp_center = np.ceil(yp) - 0.5\n",
    "    \n",
    "    # Compute differences for the erf function\n",
    "    diffx1 = (xp_center - 0.5) * dx - x\n",
    "    diffx2 = (xp_center + 0.5) * dx - x\n",
    "    diffy1 = (yp_center - 0.5) * dy - y\n",
    "    diffy2 = (yp_center + 0.5) * dy - y\n",
    "    \n",
    "    # Normalize differences by the standard deviations\n",
    "    diffx1 /= np.sqrt(2) * sxy\n",
    "    diffx2 /= np.sqrt(2) * sxy\n",
    "    diffy1 /= np.sqrt(2) * sxy\n",
    "    diffy2 /= np.sqrt(2) * sxy\n",
    "    \n",
    "    # Calculate the integrated intensity using the error function\n",
    "    intensity = np.abs(erf(diffx1) - erf(diffx2)) * np.abs(erf(diffy1) - erf(diffy2))\n",
    "    \n",
    "    return intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def gaussian_mask_small(data, spotCenter, params):\n",
    "    '''\n",
    "    runs a 2D/3D gaussian mask algorithm to localize and quantify the intensity of a fluorescent spot\n",
    "    data is the image/stack\n",
    "    all units in pix with origin at the edge of pixel i.e. leftmost corner\n",
    "    center corresponds to y = 0.5\n",
    "    spot_ctr = [x y z] : the guess center coordinates (or [x,y] in 2D)\n",
    "    params is an airlocalizeParams object holding the fit parameters\n",
    "        params.psfType : 'gaussian' or 'integratedGaussian' or 'integratedGaussianStdZ' (last option only in 3D)\n",
    "        params.psfSigma(1) : PSF width (in pixels)\n",
    "        params.psfSigma(2) : PSF height (in pixels - ignored in 2D)\n",
    "        params.fittedRegionSize : range (in PSF width units) of the region around the spot used for fitting. \n",
    "        params.maxIterations is the maximum number of iterations of the equations allowed before convergence\n",
    "        params.tol is the tolerance on the convergence (in lateral pixel dimension units)\n",
    "    '''\n",
    "    # Convert input parameters\n",
    "    xs, ys = spotCenter[:2]\n",
    "    sxy = params['psfSigma'][0]\n",
    "    tol = params['tol']\n",
    "    maxcount = params['maxIterations']\n",
    "    cutSize = params['fittedRegionSize']\n",
    "    cutwidth = [cutSize * sxy]\n",
    "    it = 0\n",
    "\n",
    "    # Initialize arrays\n",
    "    x0 = np.zeros(maxcount)\n",
    "    y0 = np.zeros(maxcount)\n",
    "    z0 = None\n",
    "    N0 = np.zeros(maxcount)\n",
    "    dist = np.zeros(maxcount)\n",
    "    x0[0], y0[0] = xs, ys\n",
    "\n",
    "    # Handle 3D data\n",
    "    if data.ndim == 3:\n",
    "        zs = spotCenter[2]\n",
    "        sz = params['psfSigma'][1]\n",
    "        cutwidth.append(cutSize * sz)\n",
    "        z0 = np.zeros(maxcount)\n",
    "        z0[0] = zs\n",
    "\n",
    "    # Compute boundaries of the ROI\n",
    "    # print(data.shape)\n",
    "    _, ROIlimits = compute_ROI_boundaries(data.shape, [x0[it], y0[it]] + ([z0[it]] if data.ndim == 3 else []), cutwidth, 0, 'small')\n",
    "    # Select sub-data within ROI\n",
    "    if data.ndim == 3:\n",
    "        # Compute ROI boundaries for 3D data\n",
    "        xp_min, xp_max = int(ROIlimits[0, 0]), int(ROIlimits[1, 0])\n",
    "        yp_min, yp_max = int(ROIlimits[0, 1]), int(ROIlimits[1, 1])\n",
    "        zp_min, zp_max = int(ROIlimits[0, 2]), int(ROIlimits[1, 2])\n",
    "\n",
    "        # Generating the grid within ROI and selecting sub-data\n",
    "        xp, yp, zp = np.meshgrid(range(xp_min, xp_max), range(yp_min, yp_max), range(zp_min, zp_max), indexing='ij')\n",
    "        sdata = data[xp_min:xp_max, yp_min:yp_max, zp_min:zp_max]\n",
    "    else:\n",
    "        # Compute ROI boundaries for 2D data\n",
    "        xp_min, xp_max = int(ROIlimits[0, 0]), int(ROIlimits[1, 0])\n",
    "        yp_min, yp_max = int(ROIlimits[0, 1]), int(ROIlimits[1, 1])\n",
    "        # Generating the grid within ROI and selecting sub-data\n",
    "        xp, yp = np.meshgrid(range(xp_min, xp_max), range(yp_min, yp_max), indexing='ij')\n",
    "        sdata = data[xp_min:xp_max, yp_min:yp_max]\n",
    "\n",
    "    # Loop through iterations\n",
    "    it = 1\n",
    "    dx, dy, dz = 1, 1, 1\n",
    "    tol = tol * (dx + dy) / 2.0\n",
    "    tmp = tol + 1\n",
    "    while it < maxcount and tmp > tol:\n",
    "        # Initializations for the iteration\n",
    "        x, y = x0[it - 1], y0[it - 1]\n",
    "        if data.ndim == 3: z = z0[it - 1]\n",
    "\n",
    "        # Placeholder for the intensity calculation based on the PSF type\n",
    "        # Assume intensity calculation functions are defined elsewhere\n",
    "        if data.ndim == 3:\n",
    "            if params['psfType'] == 'gaussian':\n",
    "                intensity = intensity_gaussian3D(xp, yp, zp, x, y, z, sxy, sz, dx, dy, dz)\n",
    "            elif params['psfType'] == 'integratedGaussian':\n",
    "                intensity = intensity_integrated_gaussian3D(xp, yp, zp, x, y, z, sxy, sz, dx, dy, dz)\n",
    "            elif params['psfType'] == 'integratedGaussianStdZ':\n",
    "                intensity = intensity_integrated_gaussian3D_stdZ(xp, yp, zp, x, y, z, sxy, sz, dx, dy, dz)\n",
    "        else:\n",
    "            if params['psfType'] == 'gaussian':\n",
    "                intensity = intensity_gaussian2D(xp, yp, x, y, sxy, dx, dy)\n",
    "            elif params['psfType'] in ['integratedGaussian', 'integratedGaussianStdZ']:\n",
    "                intensity = intensity_integrated_gaussian2D(xp, yp, x, y, sxy, dx, dy)\n",
    "        \n",
    "        intsum = np.sum(intensity * sdata)\n",
    "        sumsum = np.sum(intensity**2)\n",
    "\n",
    "        sumx = np.sum((xp - 0.5) * intensity * sdata)\n",
    "        sumy = np.sum((yp - 0.5) * intensity * sdata)\n",
    "        if data.ndim == 3: sumz = np.sum(zp * intensity * sdata)\n",
    "\n",
    "        if intsum <= 0 or sumsum == 0:\n",
    "            x0[it], y0[it], N0[it] = -1, -1, -1\n",
    "            if data.ndim == 3: z0[it] = -1\n",
    "        else:\n",
    "            x0[it] = sumx / intsum\n",
    "            y0[it] = sumy / intsum\n",
    "            if data.ndim == 3: z0[it] = sumz / intsum\n",
    "\n",
    "            N0[it] = intsum / sumsum\n",
    "\n",
    "            # Location_out_of_ROI check\n",
    "            is_outside = False  # Flag to indicate if the location is outside the ROI\n",
    "            x0_current, y0_current = x0[it], y0[it]\n",
    "            if x0_current / dx < xp_min - 1 or x0_current / dx >= xp_max: is_outside = True\n",
    "            if y0_current / dy < yp_min - 1 or y0_current / dy >= yp_max: is_outside = True\n",
    "            if data.ndim == 3:\n",
    "                z0_current = z0[it]\n",
    "                if z0_current / dz < zp_min - 1 or z0_current / dz >= zp_max: is_outside = True\n",
    "\n",
    "            # If the location is determined to be outside the ROI, update the values to -1\n",
    "            if is_outside:\n",
    "                x0[it], y0[it], N0[it] = -1, -1, -1\n",
    "                if data.ndim == 3: z0[it] = -1\n",
    "\n",
    "        # Update distance and prepare for the next iteration\n",
    "        if data.ndim == 3: dist[it] = np.sqrt((x - x0[it])**2 + (y - y0[it])**2 + (z - z0[it])**2)\n",
    "        else: dist[it] = np.sqrt((x - x0[it])**2 + (y - y0[it])**2)\n",
    "\n",
    "        tmp = dist[it]\n",
    "        if x0[it] == -1: tmp = tol - 1  # Force exit if the location is out of ROI\n",
    "\n",
    "        it += 1\n",
    "\n",
    "\n",
    "    x0 = x0[it - 1]\n",
    "    y0 = y0[it - 1]\n",
    "    if data.ndim == 3: z0 = z0[it - 1]\n",
    "\n",
    "    N0 = N0[it - 1]\n",
    "    dist = dist[it - 1]\n",
    "    \n",
    "    # Select the relevant sub-array from the data based on the ROI boundaries for error computation\n",
    "    err0 = np.sqrt(np.sum((N0 * intensity - sdata) ** 2))\n",
    "\n",
    "    # intensity calculation\n",
    "    if data.ndim == 3:\n",
    "        if params['psfType'] == 'integratedGaussian':\n",
    "            N0 *= 8\n",
    "        elif params['psfType'] == 'integratedGaussianStdZ':\n",
    "            # Define a grid around the estimated center\n",
    "            x = np.arange(np.floor(x0 - 3 * sxy), np.ceil(x0 + 3 * sxy) + 1)\n",
    "            y = np.arange(np.floor(y0 - 3 * sxy), np.ceil(y0 + 3 * sxy) + 1)\n",
    "            z = np.arange(np.floor(z0 - 3 * sz), np.ceil(z0 + 3 * sz) + 1)\n",
    "            xx, yy, zz = np.meshgrid(y, x, z, indexing='ij')\n",
    "            xx = np.ceil(xx) - 0.5\n",
    "            yy = np.ceil(yy) - 0.5\n",
    "            zz = np.round(zz)\n",
    "            # Calculate the integrated intensity\n",
    "            Itot = intensity_integrated_gaussian3D_stdZ(xx, yy, zz, x0, y0, z0, sxy, sz, 1, 1, 1)\n",
    "            N0 *= np.sum(Itot)\n",
    "        elif params['psfType'] == 'gaussian':\n",
    "            # Similar grid definition as above\n",
    "            xx, yy, zz = np.meshgrid(y, x, z, indexing='ij')\n",
    "            xx = np.ceil(xx) - 0.5\n",
    "            yy = np.ceil(yy) - 0.5\n",
    "            zz = np.round(zz)\n",
    "            # Calculate the Gaussian intensity\n",
    "            Itot = intensity_gaussian3D(xx, yy, zz, x0, y0, z0, sxy, sz, 1, 1, 1)\n",
    "            N0 *= np.sum(Itot)\n",
    "    else:\n",
    "        if params['psfType'] == 'integratedGaussian':\n",
    "            N0 *= 4\n",
    "        elif params['psfType'] == 'integratedGaussianStdZ':\n",
    "            N0 *= 4  # Assuming this is the same adjustment as for integratedGaussian in 2D\n",
    "        elif params['psfType'] == 'gaussian':\n",
    "            # Define a 2D grid around the estimated center\n",
    "            x = np.arange(np.floor(x0 - 3 * sxy), np.ceil(x0 + 3 * sxy) + 1)\n",
    "            y = np.arange(np.floor(y0 - 3 * sxy), np.ceil(y0 + 3 * sxy) + 1)\n",
    "            xx, yy = np.meshgrid(y, x, indexing='ij')\n",
    "            xx = np.ceil(xx) - 0.5\n",
    "            yy = np.ceil(yy) - 0.5\n",
    "            # Calculate the Gaussian intensity\n",
    "            Itot = intensity_gaussian2D(xx, yy, x0, y0, sxy, 1, 1)\n",
    "            N0 *= np.sum(Itot)\n",
    "\n",
    "    return x0, y0, z0, N0, err0, dist, it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gaussian_fit_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def gauss2D(Coeffs, pts):\n",
    "    \"\"\"\n",
    "    Calculate the 2D Gaussian intensity.\n",
    "\n",
    "    Args:\n",
    "    - Coeffs: Coefficients for the Gaussian calculation. An array where:\n",
    "        - Coeffs[0] is Imax, \n",
    "        - Coeffs[1] is background intensity (bg), \n",
    "        - Coeffs[2] is standard deviation in x and y (sxy),\n",
    "        - Coeffs[3] is center in x (xc),\n",
    "        - Coeffs[4] is center in y (yc).\n",
    "    - pts: Points where the Gaussian intensity should be calculated. A 2D array \n",
    "           where the first dimension is for different points, and the second dimension \n",
    "           represents [r, c], corresponding to rows and columns.\n",
    "\n",
    "    Returns:\n",
    "    - I: The calculated Gaussian intensity for each point.\n",
    "    \"\"\"\n",
    "    gridSize = pts.shape[1]\n",
    "    r = pts[:, :gridSize//2]\n",
    "    c = pts[:, gridSize//2:]\n",
    "\n",
    "    # Assuming intensity_gaussian2D is defined elsewhere and works similarly to the MATLAB version.\n",
    "    I = Coeffs[1] + Coeffs[0] * intensity_gaussian2D(r, c, Coeffs[3], Coeffs[4], Coeffs[2], 1, 1)\n",
    "\n",
    "    return I\n",
    "\n",
    "\n",
    "def gauss_integrated2D(Coeffs, pts):\n",
    "    \"\"\"\n",
    "    Calculate the integrated 2D Gaussian intensity.\n",
    "\n",
    "    Args:\n",
    "    - Coeffs: Coefficients for the Gaussian calculation. An array where:\n",
    "        - Coeffs[0] is Imax,\n",
    "        - Coeffs[1] is background intensity (bg),\n",
    "        - Coeffs[2] is standard deviation in x and y (sxy),\n",
    "        - Coeffs[3] is center in x (xc),\n",
    "        - Coeffs[4] is center in y (yc).\n",
    "    - pts: Points where the Gaussian intensity should be calculated. A 2D array\n",
    "           where the first dimension is for different points, and the second dimension\n",
    "           represents [r, c], corresponding to rows and columns.\n",
    "\n",
    "    Returns:\n",
    "    - I: The calculated integrated Gaussian intensity for each point.\n",
    "    \"\"\"\n",
    "    gridSize = pts.shape[1]\n",
    "    r = pts[:, :gridSize//2]\n",
    "    c = pts[:, gridSize//2:]\n",
    "\n",
    "    # Compute max intensity so prefactor (Coeffs[0]) is actually Imax.\n",
    "    I0 = intensity_integrated_gaussian2D(1, 1, 0.5, 0.5, Coeffs[2], 1, 1)\n",
    "\n",
    "    # Compute intensity over all data points.\n",
    "    I = Coeffs[1] + Coeffs[0] * intensity_integrated_gaussian2D(\n",
    "        r, c, Coeffs[3], Coeffs[4], Coeffs[2], 1, 1) / I0\n",
    "\n",
    "    return I\n",
    "\n",
    "\n",
    "def gauss3D(Coeffs, pts):\n",
    "    \"\"\"\n",
    "    Calculate the 3D Gaussian intensity.\n",
    "\n",
    "    Args:\n",
    "    - Coeffs: Coefficients for the Gaussian calculation. An array where:\n",
    "        - Coeffs[0] is Imax, \n",
    "        - Coeffs[1] is background intensity (bg), \n",
    "        - Coeffs[2] is standard deviation in x and y (sxy),\n",
    "        - Coeffs[3] is standard deviation in z (sz),\n",
    "        - Coeffs[4] is center in x (xc),\n",
    "        - Coeffs[5] is center in y (yc),\n",
    "        - Coeffs[6] is center in z (zc).\n",
    "    - pts: Points where the Gaussian intensity should be calculated. A 3D array \n",
    "           where the first dimension is for different points, and the second dimension \n",
    "           represents [r, c, h], corresponding to rows, columns, and height.\n",
    "\n",
    "    Returns:\n",
    "    - I: The calculated Gaussian intensity for each point.\n",
    "    \"\"\"\n",
    "    gridSize = pts.shape[1]\n",
    "    r = pts[:, :gridSize//3]\n",
    "    c = pts[:, gridSize//3:2*gridSize//3]\n",
    "    h = pts[:, 2*gridSize//3:]\n",
    "\n",
    "    # Assuming intensity_gaussian3D is defined elsewhere and works similarly to the MATLAB version.\n",
    "    I = Coeffs[1] + Coeffs[0] * intensity_gaussian3D(r, c, h, Coeffs[4], Coeffs[5], Coeffs[6], Coeffs[2], Coeffs[3], 1, 1, 1)\n",
    "\n",
    "    return I\n",
    "\n",
    "\n",
    "def gauss_integrated3D(Coeffs, pts):\n",
    "    \"\"\"\n",
    "    Calculate the integrated 3D Gaussian intensity.\n",
    "\n",
    "    Args:\n",
    "    - Coeffs: Coefficients for the Gaussian calculation. An array where:\n",
    "        - Coeffs[0] is Imax, \n",
    "        - Coeffs[1] is background intensity (bg), \n",
    "        - Coeffs[2] is standard deviation in x and y (sxy),\n",
    "        - Coeffs[3] is standard deviation in z (sz),\n",
    "        - Coeffs[4] is center in x (xc),\n",
    "        - Coeffs[5] is center in y (yc),\n",
    "        - Coeffs[6] is center in z (zc).\n",
    "    - pts: Points where the Gaussian intensity should be calculated. A 3D array \n",
    "           where the first dimension is for different points, and the second dimension \n",
    "           represents [r, c, h], corresponding to rows, columns, and planes.\n",
    "\n",
    "    Returns:\n",
    "    - I: The calculated integrated Gaussian intensity for each point.\n",
    "    \"\"\"\n",
    "    gridSize = pts.shape[1]\n",
    "    r = pts[:, :gridSize//3]\n",
    "    c = pts[:, gridSize//3:2*gridSize//3]\n",
    "    h = pts[:, 2*gridSize//3:]\n",
    "\n",
    "    # Compute max intensity so prefactor (Coeffs[1]) is actually Imax.\n",
    "    # Assuming intensity_integrated_gaussian3D is defined elsewhere and correctly adapted from MATLAB.\n",
    "    I0 = intensity_integrated_gaussian3D(1, 1, 1, 0.5, 0.5, 1, Coeffs[2], Coeffs[3], 1, 1, 1)\n",
    "\n",
    "    # Compute intensity over all data points.\n",
    "    I = Coeffs[1] + Coeffs[0] * intensity_integrated_gaussian3D(\n",
    "        r, c, h, Coeffs[4], Coeffs[5], Coeffs[6], Coeffs[2], Coeffs[3], 1, 1, 1) / I0\n",
    "\n",
    "    return I\n",
    "\n",
    "\n",
    "def gauss_integrated3D_stdZ(Coeffs, pts):\n",
    "    \"\"\"\n",
    "    Calculate the integrated 3D Gaussian intensity with standardized z-dimension.\n",
    "\n",
    "    Args:\n",
    "    - Coeffs: Coefficients for the Gaussian calculation. An array where:\n",
    "        - Coeffs[0] is Imax,\n",
    "        - Coeffs[1] is background intensity (bg),\n",
    "        - Coeffs[2] is standard deviation in x and y (sxy),\n",
    "        - Coeffs[3] is standard deviation in z (sz),\n",
    "        - Coeffs[4] is center in x (xc),\n",
    "        - Coeffs[5] is center in y (yc),\n",
    "        - Coeffs[6] is center in z (zc).\n",
    "    - pts: Points where the Gaussian intensity should be calculated. A 3D array\n",
    "           where the first dimension is for different points, and the second dimension\n",
    "           represents [r, c, h], corresponding to rows, columns, and planes.\n",
    "\n",
    "    Returns:\n",
    "    - I: The calculated integrated Gaussian intensity for each point.\n",
    "    \"\"\"\n",
    "    gridSize = pts.shape[1]\n",
    "    r = pts[:, :gridSize//3]\n",
    "    c = pts[:, gridSize//3:2*gridSize//3]\n",
    "    h = pts[:, 2*gridSize//3:]\n",
    "\n",
    "    # Compute max intensity so prefactor (Coeffs[0]) is actually Imax.\n",
    "    I0 = intensity_integrated_gaussian3D_stdZ(\n",
    "        1, 1, 1, 0.5, 0.5, 1, Coeffs[2], Coeffs[3], 1, 1, 1)\n",
    "\n",
    "    # Compute intensity over all data points.\n",
    "    I = Coeffs[1] + Coeffs[0] * intensity_integrated_gaussian3D_stdZ(\n",
    "        r, c, h, Coeffs[4], Coeffs[5], Coeffs[6], Coeffs[2], Coeffs[3], 1, 1, 1) / I0\n",
    "\n",
    "    return I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "\n",
    "def gaussian_fit_local(alData, spotCenter, params, background_correction):\n",
    "    \"\"\"\n",
    "    Performs Gaussian fitting on local image data.\n",
    "\n",
    "    Parameters:\n",
    "    - alData: Contains the image data and movie flag.\n",
    "    - spotCenter: Guess center coordinates [x, y] or [x, y, z].\n",
    "    - params: Fit parameters.\n",
    "    - background_correction: Flag for background correction (1 or 0).\n",
    "\n",
    "    Returns:\n",
    "    - Gaussout: Array with the fitting results.\n",
    "    \"\"\"\n",
    "    dx = dy = 1  # Assuming unity voxel dimensions for simplicity\n",
    "    numDim = alData['img'].ndim\n",
    "    xc, yc = spotCenter[0], spotCenter[1]\n",
    "    zc = spotCenter[2] if numDim == 3 else None\n",
    "\n",
    "    if alData['img'].ndim == 3: nx, ny, nz = alData['img'].shape\n",
    "    else: nx, ny = alData['img'].shape[:2]  # Only extract the first two dimensions\n",
    "\n",
    "\n",
    "    # Set default or use provided parameters\n",
    "    sxy = params.get('psfSigma', [2.0])[0] / dx\n",
    "    sz = params.get('psfSigma', [2.0, 2.0])[1] / dy if numDim == 3 else 2.0\n",
    "    cutSize = params.get('fittedRegionSize', 3)\n",
    "    tol = params.get('tol', 1e-6)\n",
    "    maxcount = params.get('maxIterations', 200)\n",
    "    psfType = params.get('psfType', 'integratedGaussianStdZ' if numDim == 3 else 'integratedGaussian')\n",
    "    \n",
    "    # Generate data and perform background correction\n",
    "    _, data, new_ctr, ROIlimits, _, plfit, _ = gen_linear_interpol(alData, spotCenter, [cutSize * sxy, cutSize * sz] if numDim == 3 else cutSize * sxy, 1, 'large')\n",
    "\n",
    "    if background_correction:\n",
    "        if numDim == 2:\n",
    "            xmin, ymin = ROIlimits[0, 0], ROIlimits[0, 1]\n",
    "            xc2, yc2 = new_ctr[0], new_ctr[1]\n",
    "\n",
    "            nrows, ncols = data.shape[:2]\n",
    "            r, c = np.meshgrid(np.arange(1, ncols+1), np.arange(1, nrows+1), indexing='ij')\n",
    "            c = np.ceil(c) - 0.5\n",
    "            r = np.ceil(r) - 0.5\n",
    "            pts = np.vstack([r.ravel(), c.ravel()]).T  # Transposing to get [r c] pairs\n",
    "            xmax = xmin + data.shape[0] - 1\n",
    "            ymax = ymin + data.shape[1] - 1\n",
    "\n",
    "        elif numDim == 3:\n",
    "            xmin, ymin, zmin = ROIlimits[0, 0], ROIlimits[0, 1], ROIlimits[0, 2]\n",
    "            xc2, yc2, zc2 = new_ctr[0], new_ctr[1], new_ctr[2]\n",
    "\n",
    "            nrows, ncols, nups = data.shape\n",
    "            r, c, h = np.meshgrid(np.arange(1, ncols+1), np.arange(1, nrows+1), np.arange(1, nups+1), indexing='ij')\n",
    "            c = np.ceil(c) - 0.5\n",
    "            r = np.ceil(r) - 0.5\n",
    "            h = np.round(h)\n",
    "            pts = np.vstack([r.ravel(), c.ravel(), h.ravel()]).T  # Transposing to get [r c h] triplets\n",
    "            xmax = xmin + data.shape[0] - 1\n",
    "            ymax = ymin + data.shape[1] - 1\n",
    "            zmax = zmin + data.shape[2] - 1\n",
    "    else:\n",
    "        npix = [np.ceil(cutSize * sxy), np.ceil(cutSize * sxy), np.ceil(cutSize * sz)] if numDim == 3 and not alData['isMovie'] else [np.ceil(cutSize * sxy), np.ceil(cutSize * sxy)]\n",
    "        xmin = max(int(np.ceil(xc) - npix[0]), 0)\n",
    "        xmax = min(int(np.ceil(xc) + npix[0]), nx - 1)  # Python indexing is 0-based\n",
    "        ymin = max(int(np.ceil(yc) - npix[1]), 0)\n",
    "        ymax = min(int(np.ceil(yc) + npix[1]), ny - 1)\n",
    "\n",
    "        if numDim == 3:\n",
    "            zmin = max(int(np.ceil(zc) - npix[2]), 0)\n",
    "            zmax = min(int(np.ceil(zc) + npix[2]), nz - 1)\n",
    "            data = alData['img'][xmin:xmax+1, ymin:ymax+1, zmin:zmax+1]\n",
    "            r, c, h = np.meshgrid(range(xmin, xmax+1), range(ymin, ymax+1), range(zmin, zmax+1), indexing='ij')\n",
    "            c = np.ceil(c) - 0.5\n",
    "            r = np.ceil(r) - 0.5\n",
    "            h = np.round(h)\n",
    "            pts = np.vstack([r.ravel(), c.ravel(), h.ravel()]).T\n",
    "            xc2 = xc - (xmin + 0.5)\n",
    "            yc2 = yc - (ymin + 0.5)\n",
    "            zc2 = zc - (zmin + 0.5)\n",
    "        else:\n",
    "            data = alData['img'][xmin:xmax+1, ymin:ymax+1]\n",
    "            r, c = np.meshgrid(range(xmin, xmax+1), range(ymin, ymax+1), indexing='ij')\n",
    "            pts = np.vstack([r.ravel(), c.ravel()]).T - 0.5\n",
    "            xc2 = xc - (xmin + 0.5)\n",
    "            yc2 = yc - (ymin + 0.5)\n",
    "\n",
    "    # defining guess values of the fit parameters, their acceptable range, and other fit options\n",
    "    bgmin = np.min(data)\n",
    "    bg = np.median(data)\n",
    "    Imax = np.max(data) - bg\n",
    "\n",
    "    if numDim == 3:\n",
    "        Coeffs = [Imax, bg, sxy, sz, xc2, yc2, zc2]\n",
    "        lb = [0, bgmin, 0.1, 0.1, 0, 0, 0]\n",
    "        ub = [5 * Imax, 0.5 * Imax + bg, (xmax - xmin) / 2, (zmax - zmin) / 2, xmax - xmin + 1, ymax - ymin + 1, zmax - zmin + 1]\n",
    "    else:\n",
    "        Coeffs = [Imax, bg, sxy, xc2, yc2]\n",
    "        lb = [0, bgmin, 0.1, 0, 0]\n",
    "        ub = [5 * Imax, 0.5 * Imax + bg, (xmax - xmin) / 2, xmax - xmin + 1, ymax - ymin + 1]\n",
    "\n",
    "    # Setting the appropriate fitting function\n",
    "    if numDim == 3:\n",
    "        if psfType == 'gaussian': hfun = gauss3D\n",
    "        elif psfType == 'integratedGaussian': hfun = gauss_integrated3D\n",
    "        elif psfType == 'integratedGaussianStdZ': hfun = gauss_integrated3D_stdZ\n",
    "    elif numDim == 2:\n",
    "        if psfType == 'gaussian': hfun = gauss2D\n",
    "        elif psfType == 'integratedGaussian': hfun = gauss_integrated2D\n",
    "        elif psfType == 'integratedGaussianStdZ': hfun = gauss_integrated2D\n",
    "\n",
    "\n",
    "    # Actual fit\n",
    "    Gaussout, cov = curve_fit(hfun, pts, data, p0=Coeffs, bounds=(lb, ub), kwargs={'maxfev': maxcount, 'xtol': tol})\n",
    "    \n",
    "    if numDim == 3 and not alData.isMovie:\n",
    "        if psfType == 'gaussian':\n",
    "            xc, yc, zc = Gaussout[4], Gaussout[5], Gaussout[6]\n",
    "            sxy, sz = Gaussout[2], Gaussout[3]\n",
    "            x = np.arange(np.floor(xc - 3*sxy), np.ceil(xc + 3*sxy) + 1)\n",
    "            y = np.arange(np.floor(yc - 3*sxy), np.ceil(yc + 3*sxy) + 1)\n",
    "            z = np.arange(np.floor(zc - 3*sz), np.ceil(zc + 3*sz) + 1)\n",
    "            xx, yy, zz = np.meshgrid(y, x, z, indexing='ij')\n",
    "            pts2 = np.stack([np.ceil(xx)-0.5, np.ceil(yy)-0.5, np.round(zz)], axis=-1).reshape(-1, 3)\n",
    "            bg = Gaussout[1]\n",
    "            Gaussout[1] = 0\n",
    "            Itot = np.sum(gauss3D(Gaussout, pts2))\n",
    "            Gaussout[1] = bg\n",
    "        elif psfType == 'integratedGaussian':\n",
    "            I0 = intensity_integrated_gaussian3D(1, 1, 1, 0.5, 0.5, 1, Gaussout[2], Gaussout[3], 1, 1, 1)\n",
    "            Itot = 8*Gaussout[0]/I0\n",
    "        elif psfType == 'integratedGaussianStdZ':\n",
    "            xc, yc, zc = Gaussout[4], Gaussout[5], Gaussout[6]\n",
    "            sxy, sz = Gaussout[2], Gaussout[3]\n",
    "            x = np.arange(np.floor(xc - 3*sxy), np.ceil(xc + 3*sxy) + 1)\n",
    "            y = np.arange(np.floor(yc - 3*sxy), np.ceil(yc + 3*sxy) + 1)\n",
    "            z = np.arange(np.floor(zc - 3*sz), np.ceil(zc + 3*sz) + 1)\n",
    "            xx, yy, zz = np.meshgrid(y, x, z, indexing='ij')\n",
    "            pts2 = np.stack([np.ceil(xx)-0.5, np.ceil(yy)-0.5, np.round(zz)], axis=-1).reshape(-1, 3)\n",
    "            bg = Gaussout[1]\n",
    "            Gaussout[1] = 0\n",
    "            Itot = np.sum(gauss_integrated3D_stdZ(Gaussout, pts2))\n",
    "            Gaussout[1] = bg\n",
    "\n",
    "        Gaussout = np.append(Gaussout, [Itot, np.sqrt(cov)])\n",
    "\n",
    "    elif numDim == 2:\n",
    "        if psfType == 'gaussian':\n",
    "            xc, yc, sxy = Gaussout[3], Gaussout[4], Gaussout[2]\n",
    "            x = np.arange(np.floor(xc - 3*sxy), np.ceil(xc + 3*sxy) + 1)\n",
    "            y = np.arange(np.floor(yc - 3*sxy), np.ceil(yc + 3*sxy) + 1)\n",
    "            xx, yy = np.meshgrid(y, x, indexing='ij')\n",
    "            pts2 = np.stack([np.ceil(xx)-0.5, np.ceil(yy)-0.5], axis=-1).reshape(-1, 2)\n",
    "            bg = Gaussout[1]\n",
    "            Gaussout[1] = 0\n",
    "            Itot = np.sum(gauss2D(Gaussout, pts2))\n",
    "            Gaussout[1] = bg\n",
    "        elif psfType == 'integratedGaussian':\n",
    "            I0 = intensity_integrated_gaussian2D(1, 1, 0.5, 0.5, Gaussout[2], 1, 1)\n",
    "            Itot = 4*Gaussout[0]/I0\n",
    "\n",
    "        # Update Gaussout with the total integrated intensity and the square root of the residual norm.\n",
    "        Gaussout = np.append(Gaussout, [Itot, np.sqrt(cov)])\n",
    "\n",
    "\n",
    "    # Correcting the center position for the offset of the substack used for the fit\n",
    "    if numDim == 3:\n",
    "        Gaussout[4] = Gaussout[4] - 1 + xmin  # Adjust x center\n",
    "        Gaussout[5] = Gaussout[5] - 1 + ymin  # Adjust y center\n",
    "        Gaussout[6] = Gaussout[6] - 1 + zmin  # Adjust z center\n",
    "    else:\n",
    "        Gaussout[3] = Gaussout[3] - 1 + xmin  # Adjust x center for 2D\n",
    "        Gaussout[4] = Gaussout[4] - 1 + ymin  # Adjust y center for 2D\n",
    "\n",
    "    # Adding the extra parameters from the background equation to the output\n",
    "    if background_correction == 1:\n",
    "        if numDim == 3: Gaussout = np.append(Gaussout, plfit[:4])  # Assuming plfit has at least 4 elements\n",
    "        else: Gaussout = np.append(Gaussout, plfit[:3])  # Assuming plfit has at least 3 elements\n",
    "\n",
    "\n",
    "    return Gaussout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# local_maxproj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_maxproj(alData, spot_ctr, params):\n",
    "    \"\"\"\n",
    "    Compute a localized maximum intensity projection around a specified spot center.\n",
    "\n",
    "    Args:\n",
    "    - alData: An object or dictionary containing the imaging data in 'img' key or attribute.\n",
    "    - spot_ctr: The center of the spot as a tuple or list, [x, y, z].\n",
    "    - params: A dictionary or object with attributes 'psfSigma' and 'fittedRegionSize', \n",
    "              specifying the standard deviation of the PSF and the size of the region to fit, respectively.\n",
    "\n",
    "    Returns:\n",
    "    - img: A 2D numpy array representing the localized maximum intensity projection.\n",
    "    \"\"\"\n",
    "    zc = spot_ctr[2]\n",
    "    cutwidth_z = np.ceil(params['psfSigma'][1] * params['fittedRegionSize'])\n",
    "    nz = alData['img'].shape[2]\n",
    "    \n",
    "    # Calculate the range of planes for the max projection\n",
    "    ROIlimits_z = np.ceil(zc) - np.floor(cutwidth_z)\n",
    "    ROIlimits_z = max(1, ROIlimits_z)  # Ensure the lower bound is within the image\n",
    "    zmax = np.ceil(zc) + np.floor(cutwidth_z)\n",
    "    zmax = min(nz, zmax)  # Ensure the upper bound is within the image\n",
    "    \n",
    "    # Perform the max projection\n",
    "    img = np.max(alData['img'][:, :, int(ROIlimits_z)-1:int(zmax)], axis=2)  # Adjusted for Python's 0-based indexing\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run_gaussian_fit_on_all_spots_in_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def run_gaussian_fit_on_all_spots_in_image(spotCandidates, alData, params, verbose=True):\n",
    "    \"\"\"\n",
    "    Translated function to run Gaussian fit on all spots in an image.\n",
    "\n",
    "    Args:\n",
    "        spotCandidates (np.ndarray): Array of spot candidates.\n",
    "        alData (dict): Dictionary containing image data and metadata.\n",
    "        params (dict): Dictionary of parameters for fitting.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the location of spots and their variables.\n",
    "    \"\"\"\n",
    "    # Initialize arrays and set cutwidth\n",
    "    nSpots = len(spotCandidates)\n",
    "    loc = None\n",
    "    locVars = None\n",
    "    cutWidth = None\n",
    "\n",
    "    if params['fitMethod'] == '3DGaussianFit':\n",
    "        loc = np.zeros((nSpots, 8))\n",
    "        locVars = ['x_in_pix', 'y_in_pix', 'z_in_pix', 'integratedIntensity', 'residuals', 'image_number']\n",
    "        cutWidth = [np.ceil(params['fittedRegionSize'] * psf) for psf in params['psfSigma']]\n",
    "\n",
    "    elif params['fitMethod'] in ['3DMaskFull', '2DMaskOnLocalMaxProj']:\n",
    "        loc = np.zeros((nSpots, 6))\n",
    "        locVars = ['x_in_pix', 'y_in_pix', 'z_in_pix', 'integratedIntensity', 'residuals', 'image_number']\n",
    "        cutWidth = [np.ceil(params['fittedRegionSize'] * psf) for psf in params['psfSigma']]\n",
    "        \n",
    "    elif params['fitMethod'] in ['2DGaussianMask', '2DGaussianFit']:\n",
    "        loc = np.zeros((nSpots, 4))\n",
    "        locVars = ['x_in_pix', 'y_in_pix', 'integratedIntensity', 'residuals', 'image_number']\n",
    "        cutWidth = np.ceil(params['fittedRegionSize'] * params['psfSigma'][0])\n",
    "    \n",
    "    else: raise ValueError(\"Unrecognized fit method\")\n",
    "\n",
    "\n",
    "    # Loop over each pre-detected spot\n",
    "    with tqdm(total=nSpots, desc=f\"Fit predetected spots\", position=0, leave=True, disable=not verbose) as pbar_sub:\n",
    "        for j in range(nSpots):\n",
    "            new_ctr = spotCandidates[j, :params['numdim']]\n",
    "            ROIlimits = None\n",
    "            # Background correction\n",
    "            if params['bgCorrectionMode'] == 'localPlane':\n",
    "                _, stack_bg_corr, new_ctr, ROIlimits, *_ = gen_linear_interpol(alData, new_ctr, cutWidth, 1, 'large')\n",
    "            elif params['bgCorrectionMode'] == 'localMedian':\n",
    "                stack_bg_corr, new_ctr, ROIlimits = subtract_median(alData, new_ctr, cutWidth, 1, mode='local')\n",
    "            elif params['bgCorrectionMode'] == 'globalMedian':\n",
    "                stack_bg_corr, new_ctr, ROIlimits = subtract_median(alData, new_ctr, cutWidth, 1, mode='global')\n",
    "            \n",
    "            # Gaussian Fit\n",
    "            if params['fitMethod'] == '3DMaskFull':\n",
    "                # print(stack_bg_corr.shape)\n",
    "                x0, y0, z0, N0, err0, *_ = gaussian_mask_small(stack_bg_corr, new_ctr, params)\n",
    "                loc[j, 0:5] = [x0 + ROIlimits[0, 0] + 1, y0 + ROIlimits[0, 1] + 1, z0 + ROIlimits[0, 2], N0, err0]\n",
    "            \n",
    "            elif params['fitMethod'] == '2DGaussianMask':\n",
    "                x0, y0, _, N0, err0, *_ = gaussian_mask_small(stack_bg_corr, new_ctr, params)\n",
    "                loc[j, 0:4] = [x0 + ROIlimits[0, 0], y0 + ROIlimits[0, 1], N0, err0]\n",
    "\n",
    "            elif params['fitMethod'] == '3DGaussianFit':\n",
    "                Gaussout = gaussian_fit_local(stack_bg_corr, new_ctr, params, 1)\n",
    "                loc[j, 0:5] = [Gaussout[4] + ROIlimits[0, 0], Gaussout[5] + ROIlimits[0, 1], Gaussout[6] + ROIlimits[0, 2], Gaussout[7], Gaussout[8]]\n",
    "\n",
    "            elif params['fitMethod'] == '2DGaussianFit':\n",
    "                Gaussout = gaussian_fit_local(stack_bg_corr, new_ctr, params, 1)\n",
    "                loc[j, 0:4] = [Gaussout[3] + ROIlimits[0, 0], Gaussout[4] + ROIlimits[0, 1], Gaussout[5], Gaussout[6]]\n",
    "\n",
    "            elif params['fitMethod'] == '2DMaskOnLocalMaxProj':\n",
    "                # Assuming local_maxproj function is defined elsewhere\n",
    "                img_bg_corr = local_maxproj(stack_bg_corr, new_ctr, params)\n",
    "                x0, y0, _, N0, err0, *_ = gaussian_mask_small(img_bg_corr, new_ctr[:2], params)\n",
    "                loc[j, 0:5] = [x0 + ROIlimits[0, 0], y0 + ROIlimits[0, 1], new_ctr[2] + ROIlimits[0, 2], N0, err0]\n",
    "\n",
    "            else:\n",
    "                print(f\"Unrecognized fit method: {params['fitMethod']}\")\n",
    "\n",
    "            pbar_sub.update(1)\n",
    "\n",
    "\n",
    "    return loc, locVars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from scipy.ndimage import binary_dilation\n",
    "import tifffile\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def create_spherical_structure(radius):\n",
    "    \"\"\"\n",
    "    Creates a 3D spherical structuring element with the given radius.\n",
    "    \n",
    "    Parameters:\n",
    "    - radius: The radius of the sphere.\n",
    "    \n",
    "    Returns:\n",
    "    - A 3D numpy array with shape (2*radius+1, 2*radius+1, 2*radius+1),\n",
    "      where elements within the specified radius are True, and others are False.\n",
    "    \"\"\"\n",
    "    # The diameter and size of the structure array\n",
    "    diameter = radius * 2 + 1\n",
    "    struct_size = (diameter, diameter, diameter)\n",
    "    \n",
    "    # Create an array of distances from the center\n",
    "    arr = np.zeros(struct_size)\n",
    "    center = np.array(struct_size) // 2\n",
    "    for z in range(diameter):\n",
    "        for y in range(diameter):\n",
    "            for x in range(diameter):\n",
    "                distance = np.sqrt((center[0] - z) ** 2 + (center[1] - y) ** 2 + (center[2] - x) ** 2)\n",
    "                if distance <= radius:\n",
    "                    arr[z, y, x] = True\n",
    "                else:\n",
    "                    arr[z, y, x] = False\n",
    "    \n",
    "    return arr.astype(np.bool_)\n",
    "\n",
    "\n",
    "def save_points(df, shape, output_tiff_path, radius=3, verbose=True):\n",
    "    # Assuming you have the `shape` of your image from the TIFF metadata\n",
    "    label_image = np.zeros(shape, dtype=np.uint16)\n",
    "\n",
    "    # Create the binary image and dilate\n",
    "    # structure = np.ones((3, 3, 3), dtype=np.bool_)\n",
    "    structure = create_spherical_structure(radius=radius)\n",
    "\n",
    "    # Vectorized setting of points in the label_image array\n",
    "    # Note: Ensure that z, x, y indices are within the bounds of the image shape\n",
    "    valid_points = (df['z_in_pix'] < shape[0]) & (df['x_in_pix'] < shape[1]) & (df['y_in_pix'] < shape[2])\n",
    "    coords = df.loc[valid_points, ['z_in_pix', 'x_in_pix', 'y_in_pix']].astype(int).values.T\n",
    "    labels = df.loc[valid_points, 'Label'].values\n",
    "\n",
    "    # Set the labels at the coordinates\n",
    "    label_image[coords[0], coords[1], coords[2]] = labels\n",
    "\n",
    "    # Apply binary dilation to label_image\n",
    "    # For each unique label, dilate separately to prevent merging\n",
    "    for label in tqdm(np.unique(labels), desc='saving points', disable=not verbose):\n",
    "        binary_mask = label_image == label\n",
    "        dilated_mask = binary_dilation(binary_mask, structure)\n",
    "        label_image[dilated_mask] = label\n",
    "\n",
    "    # Save the dilated label image to a TIFF file\n",
    "    tifffile.imwrite(output_tiff_path, label_image) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "\n",
    "def substract_with_scale(image1, image2, rawtype=np.uint16, uppertype=np.int32):\n",
    "    image1 = image1.astype(uppertype)\n",
    "    image2 = image2.astype(uppertype)\n",
    "    sub = image1 - image2\n",
    "    min_val = sub.min()\n",
    "    max_val = sub.max()\n",
    "    scaled_subtracted_image = (sub - min_val) / (max_val - min_val) * np.iinfo(rawtype).max / 2\n",
    "    scaled_subtracted_image = scaled_subtracted_image.astype(rawtype)\n",
    "    return scaled_subtracted_image\n",
    "\n",
    "\n",
    "def perform_DoG(image, dog_sigma=(0.5,1), enhance=True):\n",
    "    \"\"\"\n",
    "    Apply Difference of Gaussians (DoG) to an image.\n",
    "    \"\"\"\n",
    "    sigma1, sigma2 = dog_sigma\n",
    "    image1 = gaussian_filter(image, sigma=sigma1)\n",
    "    image2 = gaussian_filter(image, sigma=sigma2)\n",
    "    dog = substract_with_scale(image1, image2)\n",
    "    if enhance: dog = substract_with_scale(1.5 * dog, np.mean(dog))\n",
    "    return dog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_tiff(image, dtype=np.uint16):\n",
    "    \"\"\"\n",
    "    Normalize its intensity values to the range dtype / 2.\n",
    "    \"\"\"\n",
    "    # lowerbound = np.percentile(image, 0)\n",
    "    lowerbound = np.min(image)\n",
    "    upperbound = np.percentile(image, 99.99)\n",
    "    # upperbound = np.max(image)\n",
    "    normalized_image = (image - lowerbound) / (upperbound - lowerbound)\n",
    "    normalized_image = np.clip(normalized_image, 0, 1)\n",
    "    scaled_image = (normalized_image * np.iinfo(dtype).max / 2).astype(dtype)\n",
    "    return scaled_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# airlocalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from telnetlib import DO\n",
    "import numpy as np\n",
    "from skimage.io import imread, imsave\n",
    "# Assume timtiffread and smooth_image_and_subtract_background7 are previously defined functions\n",
    "\n",
    "class AirLocalizeData:\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.srcDir = ''\n",
    "        self.fList = []\n",
    "        self.curFile = ''\n",
    "        self.fileIdx = 0\n",
    "        self.img = None\n",
    "        self.smooth = None\n",
    "        # self.isMovie = False\n",
    "        # self.nFrames = 0\n",
    "        # self.curFrame = 0\n",
    "\n",
    "    def reset_current_file(self):\n",
    "        \"\"\"Resets everything but the file list and the isMovie flag.\"\"\"\n",
    "        self.curFile = ''\n",
    "        self.fileIdx = 0\n",
    "        self.img = None\n",
    "        self.smooth = None\n",
    "        # self.nFrames = 0\n",
    "        # self.curFrame = 0\n",
    "\n",
    "    def set_flist_from_params(self, params):\n",
    "        # Placeholder for setting file list from parameters\n",
    "        # This method will involve file handling and directory searching based on the parameters\n",
    "        self.srcDir = params['dataFileName']\n",
    "        self.fList = [_ for _ in os.listdir(params['dataFileName']) if _.endswith('.tif')]\n",
    "\n",
    "        \n",
    "    def set_flist(self, flist):\n",
    "        self.reset()\n",
    "        if isinstance(flist, list):\n",
    "            self.fList = flist\n",
    "        else:\n",
    "            print('Input file list has wrong format; resetting airlocalize data object.')\n",
    "\n",
    "    def get_flist(self):\n",
    "        return self.fList\n",
    "\n",
    "    def set_file_idx(self, idx):\n",
    "        if idx > len(self.fList) or idx <= 0:\n",
    "            print(f'Cannot access file index {idx}; file list has {len(self.fList)} entries.')\n",
    "            return\n",
    "        self.reset_current_file()\n",
    "        self.fileIdx = idx\n",
    "        self.curFile = self.fList[idx - 1]  # Adjust for zero-based indexing\n",
    "\n",
    "    def get_file_idx(self):\n",
    "        return self.fileIdx\n",
    "\n",
    "    def set_cur_file(self, file_name):\n",
    "        if file_name not in self.fList:\n",
    "            print(f'Desired file {file_name} is not part of existing file list; cannot set as current.')\n",
    "        else:\n",
    "            idx = self.fList.index(file_name) + 1  # Adjust for one-based indexing in the setter\n",
    "            self.set_file_idx(idx)\n",
    "\n",
    "    def get_cur_file(self):\n",
    "        return self.curFile\n",
    "\n",
    "    # def set_nframes(self):\n",
    "    #     # Logic to determine the number of frames; may involve loading the image if not already loaded\n",
    "    #     pass\n",
    "\n",
    "    # def set_cur_frame(self, new_frame):\n",
    "    #     # Logic to update the current frame; involves checking if new_frame is valid\n",
    "    #     pass\n",
    "\n",
    "    def is_file_index_img_loaded(self, idx):\n",
    "        # Checks if the image for the given index is loaded\n",
    "        pass\n",
    "\n",
    "    def retrieve_img(self, params):\n",
    "        # Placeholder for loading an image based on current file index\n",
    "        self.img = imread(os.path.join(self.srcDir, self.curFile))\n",
    "        if len(self.img.shape) == 3: self.img = np.transpose(self.img, (1, 2, 0))\n",
    "        if params['scale']: self.img = scale_tiff(self.img)\n",
    "        return self.img\n",
    "\n",
    "    def retrieve_feature_img(self, params):\n",
    "        if params['featureExtract'] == 'DoG':\n",
    "            self.smooth = perform_DoG(self.img, dog_sigma=(params['filterLo'], params['filterHi']))\n",
    "            print(f\"smoothed_{self.curFile}\")\n",
    "            imsave(os.path.join(params['saveDirName'], f\"smoothed_{self.curFile}\"), np.transpose(self.smooth, (2,0,1)))\n",
    "    # Additional methods as required\n",
    "\n",
    "# Example usage\n",
    "# air_data = AirLocalizeData()\n",
    "# air_data.set_flist(['path/to/image1.tif', 'path/to/image2.tif'])\n",
    "# air_data.set_file_idx(1)\n",
    "# print(air_data.get_cur_file())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def airlocalize(parameters_filename='parameters.yaml'):\n",
    "    # read parameters from config file\n",
    "    # parameters_filename = sys.argv[1]\n",
    "\n",
    "    with open(parameters_filename, 'r') as file:\n",
    "        params = yaml.safe_load(file)\n",
    "\n",
    "    al_data = AirLocalizeData()\n",
    "    al_data.set_flist_from_params(params)\n",
    "\n",
    "    # load file list from parameters\n",
    "    try: \n",
    "        al_data.get_flist()\n",
    "        print(f\"Found {len(al_data.fList)} files to analyze.\")\n",
    "    except: raise ValueError('could not find files to analyze.')\n",
    "    \n",
    "    # set the output dir\n",
    "    if 'saveDirName' not in params: params['saveDirName'] = os.path.dirname(al_data.flist[0])\n",
    "    os.makedirs(params['saveDirName'], exist_ok=True)\n",
    "        \n",
    "    # Open the log file\n",
    "    # log_file = open(os.path.join(params['saveDirName'], 'log.txt'), 'a')\n",
    "    # original_stdout = sys.stdout\n",
    "    # sys.stdout = log_file\n",
    "\n",
    "    # save the parameters to the output dir\n",
    "    with open(os.path.join(params['saveDirName'], 'parameters.yaml'), 'w') as file:\n",
    "        yaml.dump(params, file)\n",
    "\n",
    "    # verbose\n",
    "    verbose = True if params['verbose'] else False\n",
    "\n",
    "    # loop over files\n",
    "    for i, file in enumerate(al_data.fList, start=1):\n",
    "        al_data.set_file_idx(i)\n",
    "        print(f'Analyzing file: {al_data.curFile}...')\n",
    "\n",
    "        # Retrieve current image and smooth it\n",
    "        # overwrite = False if i == 1 else True\n",
    "        al_data.retrieve_img(params)\n",
    "        print(al_data.img.shape)\n",
    "\n",
    "        # Verify that dimensionality agrees with settings\n",
    "        nd = al_data.img.ndim  # Assuming img is a numpy array or similar\n",
    "        num_dim_expect = params['numdim']\n",
    "        if nd != num_dim_expect:\n",
    "            print(f'Current image has {nd} dimensions but expecting {num_dim_expect}D data; skipping file')\n",
    "            continue\n",
    "        \n",
    "        # Smooth the image and subtract background\n",
    "        al_data.retrieve_feature_img(params)\n",
    "\n",
    "        # Pre-detection of local maxima\n",
    "        spot_candidates = find_isolated_maxima(al_data, params, verbose)\n",
    "        \n",
    "        # Detection/quantification\n",
    "        loc, loc_vars = run_gaussian_fit_on_all_spots_in_image(spot_candidates, al_data, params)\n",
    "\n",
    "        # Save spot coordinates and detection parameters to a csv file\n",
    "        df = pd.DataFrame(loc, columns=loc_vars)\n",
    "        filename = os.path.basename(file).replace('.tif', '')\n",
    "        df.to_csv(os.path.join(params['saveDirName'], f'{filename}_spots.csv'), index=False)\n",
    "\n",
    "        # Save the spot image if needed\n",
    "        if params['output_spots_image']: \n",
    "            img_shape_reordered = (al_data.img.shape[2], al_data.img.shape[0], al_data.img.shape[1])\n",
    "            df['Label'] = [1] * len(df)\n",
    "            df = df.sort_values(by=['residuals'], ascending=True)\n",
    "            # Save the spot image\n",
    "            save_points(df=df, shape=img_shape_reordered, output_tiff_path=os.path.join(params['saveDirName'], f'{filename}_spots.tif'), radius=2, verbose=params['verbose'])\n",
    "\n",
    "    # Close the log file\n",
    "    # sys.stdout = original_stdout\n",
    "    # log_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    airlocalize(\"parameters.yaml\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
